{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability theory\n",
    "\n",
    "The objective of this notebook is to introduce <b>stochastic processes</b> ($\\approx$ sequence of random variables) and <b>filtrations</b> ($\\approx$ sequence of $\\sigma$-Alebra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "Consider a finite sample space $\\Omega = \\{ \\omega_{1}, ..., \\omega_{M} \\}, M < \\infty$, on which you define a probability measure p such that \n",
    "\n",
    "$$\\begin{equation} \n",
    "\\begin{split}\n",
    "P(\\{ \\omega_{i} \\}) &= p_{i} > 0\\\\\n",
    "\\sum_{i=1}^{M} P(\\{ \\omega_{i} \\}) &= 1\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "Definition: (Random variable) A random variable X is a mapping: $$ X:\\rightarrow \\mathbb{R} $$ and we define its expectation by: $$ E[X] = \\sum_{i=1}^{M} X(\\omega_{i})\\cdot P(\\{ \\omega_{i} \\}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigma algebras, or how to translate information rigorously?\n",
    "\n",
    "When dealing with random variable, it is important to know which information is available. This is the purpose of $\\sigma$-algebra.\n",
    "\n",
    "<b>Definition: ($\\sigma$-Algebra)</b> A collection F of subsets of $\\Omega$ is called a $\\sigma$-Algebra if the following hold:\n",
    "\n",
    "1. $\\emptyset \\in F$\n",
    "2. If $A \\in F$, then $A^{C}\\in F$\n",
    "3. If $A_{n} \\in F, \\forall n$ then $\\bigcup_{i=1}^{\\infty}A_{n} \\in F$\n",
    "\n",
    "<u>Interpretation:</u> We can see a $\\sigma$-Algebra as a set of all possible events generated by $\\Omega$ that is stable under the union and the complementarity. \n",
    "\n",
    "<u>Remark:</u> There can be many $\\sigma$-Algebra for a given set $\\Omega$. $\\mathcal{F}=\\mathcal{P}(\\Omega) is one of them.\n",
    "\n",
    "<b>Definition: (Partition)</b> A set $\\mathcal{P} = \\{ A_{1}, ..., A_{n} \\}$ of nonempty subsets of the sample space $\\Omega$ is called a (finite) partition of $\\Omega$ if\n",
    "\n",
    "1. $\\bigcup_{i=1}^{n}A_{i} = \\Omega$\n",
    "2. $A_{i}\\cap A_{j} = \\emptyset$\n",
    "\n",
    "<u>Finite case:</u> Every $\\sigma$-Algebra is generated by a partition.\n",
    "\n",
    "<b>Definition: ($\\mathcal{F}$-measurable)</b> A function $X:\\Omega \\rightarrow \\{ x_{1}, ..., x_{k} \\}$ is $\\mathcal{F}$-measurable if:\n",
    "\n",
    "$$ X^{-1}(x_{i}) \\in \\mathcal{F}, \\forall x_{i} $$\n",
    "\n",
    "<u>Interpretation:</u> It means that each $x_{i}$ is reachable from an element of $\\mathcal{F}$\n",
    "\n",
    "<u>Terminology:</u> If X is $\\mathcal{F}$-measurable, we write $X \\in \\mathcal{F}$\n",
    "\n",
    "<b>Proposition: (Stability under operations)</b> Assume that X and Y are \\mathcal{F} measurable. Then:\n",
    "1. $\\alpha X + \\beta Y \\in \\mathcal{F}$\n",
    "2. $X \\cdot Y \\in \\mathcal{F}$\n",
    "3. If $Y(\\omega)\\neq 0, \\forall \\omega$: $$\\frac{X}{Y} \\in \\mathcal{F}$$\n",
    "4. If $(X_{n})_{n=0}^{\\infty} \\in \\mathcal{F}$ then:\n",
    "\n",
    "$$ \\text{sup}_{n} X_{n} , \\text{inf}_{n} X_{n},  \\text{lim sup}_{n} X_{n}, \\text{lim inf}_{n} X_{n} \\in \\mathcal{F}$$\n",
    "\n",
    "<b> Definition: (Smallest $\\sigma$-Algebra)</b>\n",
    "\n",
    "1. Let $X:\\Omega \\in \\mathbb{R}$. Then $\\mathcal{F}=\\sigma(X)$ is the smallest \\sigma-Algebra such that $X$ is $\\mathcal{F}$-measurable. \n",
    "2. Let $X_{i}:\\Omega \\in \\mathbb{R}$. Then $\\mathcal{G}=\\sigma(X_{1}, ..., X_{n})$ is the smallest $\\sigma$-Algebra such that $X_{1}, ..., X_{n}$ is $\\mathcal{F}$-measurable.\n",
    "\n",
    "<b> Proposition:</b> Let $X_{1}, ..., X_{n}$ be mappings such that $X_{i}:\\Omega \\rightarrow \\mathbb{R}$. Assume that the mapping $Z:\\Omega \\rightarrow \\mathbb{R}$ is $\\sigma(X_{1}, ..., X_{n})$-measurable. Then there exists a function $f:\\mathbb{R}^{n}\\rightarrow \\mathbb{R}$ such that:\n",
    "\n",
    "$$ Z(\\omega) = f(X_{1}(\\omega), ..., X_{n}(\\omega))$$\n",
    "\n",
    "<u>Interpretation:</u> This means that $Z$ is completely determined by the information in the $\\sigma$-Algebra.\n",
    "\n",
    "<b>Definition: (Independent $\\sigma$-Algebra)</b> The $\\sigma$-Algebras $\\mathcal{F}_{1}, ..., \\mathcal{F}_{n}$ are independent if:\n",
    "\n",
    "$$ P(\\bigcup_{i=1}^{n}A_{i}) = \\Pi_{i=1}^{n}P(A_{i}), \\forall A_{i} \\in \\mathcal{F}_{i}$$\n",
    "\n",
    "<b>Definition: (Independent random variables)</b> Random variables $X_{1}, ..., X_{n}$ are independent if $\\sigma(X_{1}), ..., \\sigma(X_{n})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic processes\n",
    "\n",
    "<b>TL;DR:</b> Stochastic processes are sequences of random events.\n",
    "\n",
    "<b>Definition: (Stochastic process)</b> A stochastic process $\\{(S_{n})_{n=0}^{\\infty} \\}$  on the probability space  $(\\Omega, \\mathcal{F}, P)$ is a mapping:\n",
    "\n",
    "$$ S:\\mathbb{N} \\times \\Omega \\rightarrow \\mathbb{R} $$ \n",
    "\n",
    "such that for each $n \\in \\mathbb{N}$:\n",
    "\n",
    "$$ S_{n}(.):\\Omega \\rightarrow \\mathbb{R} $$\n",
    "\n",
    "is $\\mathcal{F}$-measurable.\n",
    "\n",
    "<u>Remarks:</u> \n",
    "- For $n$ fixed: $\\omega \\rightarrow S(n, \\omega)$ is a random variable\n",
    "- For $\\omega$ fixed: $n \\rightarrow S(n, \\omega)$ is a deterministic function of time, called the realization or the sample path.\n",
    "\n",
    "<u>Note:</u> We will consider only finite processes $\\{ S_{n} \\}_{n=0}^{\\infty}$\n",
    "\n",
    "<b>Definition: (Known information at time t)</b> Let $\\{ S_{n} \\}_{n=0}^{\\infty}$ be a stochastic process on (\\Omega, \\mathcal{F}, P). The  $\\sigma$ Algebra generated by S over [0, T] is defined by \n",
    "\n",
    "$$ \\mathcal{F}_{t}^{S} = \\sigma\\{ S_{n}: n \\leq t \\}$$\n",
    "\n",
    "<u>Interpretation: </u> $\\mathcal{F}_{t}^{S}$ is the information generated by observing S over the time interval $[0, t]$.\n",
    "\n",
    "<u>Remark:</u>More generally information developing over time is formalized by filtrations. They are families\n",
    "of increasing $\\sigma$-algebras.\n",
    "\n",
    "<b>Definition: (Filtration)</b> A filtration $\\underline{\\mathcal{F}} = \\{\\mathcal{F}_{n} \\}_{n=0}^{\\infty}$ on $(\\Omega, \\mathcal{F}, P)$ is an indexed family of $\\sigma$-algebras on $\\Omega$ such that \n",
    "\n",
    "1. $\\mathcal{F}_{n} \\subseteq \\mathcal{F}, \\forall n \\geq 0$\n",
    "2. $m \\geq n \\Rightarrow \\mathcal{F}_{m} \\subseteq \\mathcal{F}_{n}$\n",
    "\n",
    "<b>Definition: (Measurability for filtration)</b> Given a filtration $\\underline{\\mathcal{F}}$ and a random process $S$ on $(\\Omega, \\mathcal{F}, P)$ we say that \n",
    "\n",
    "1. $S$ is adapted to $\\underline{\\mathcal{F}}$ if \n",
    "$$ S_{n} \\in \\mathcal{F}_{n}, \\forall n \\geq 0 $$\n",
    "\n",
    "2. $S$ is predictable with respect to $\\underline{\\mathcal{F}}$ if \n",
    "$$ S_{n} \\in \\mathcal{F}_{n-1}, \\forall n \\geq 0 $$\n",
    "\n",
    "<u>Interpretation:</u>\n",
    "1. At time $n$ (today typically), the random variable $S_{n}$ is measurable (and has the ensuing benefits).\n",
    "2. At time $n$ (today typically), the random variable $S_{n+1}$ (tomorrow typically) is $\\mathcal{F}_{n}$-measurable (in today's measurability!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional expectation\n",
    "\n",
    "Let $X$ be a random variable on $(\\Omega, \\mathcal{F}, P)$ and $\\mathcal{G}$ a $\\sigma$-Algebra such that $\\mathcal{G} \\subseteq \\mathcal{F}$ \n",
    "\n",
    "In this section, we aim to define the expectation of $X$ given the information in $\\mathcal{G}$\n",
    "\n",
    "$$ E[ X \\mid \\mathcal{G}] $$\n",
    "\n",
    "We will define three key concepts:\n",
    "\n",
    "- The conditional expectation of $X$ given $B \\in \\mathcal{F}, P(B)\\neq 0$\n",
    "- The conditional expectation of $X$ given a partition $\\mathcal{P}$ of $\\mathcal{F}$\n",
    "- The conditional expectation of $X$ given $\\mathcal{G}$\n",
    "\n",
    "### The conditional expectation of $X$ given $B \\in \\mathcal{F}, P(B)\\neq 0$\n",
    "\n",
    "<b>Definition:</b>\n",
    "\n",
    "$$ E[X\\sim B] = \\sum_{\\omega_{i} \\in B} X(\\omega_{i}\\cdot \\frac{P(\\omega_{i})}{P(B)}) = \\frac{1}{P(B)}\\sum_{\\omega \\in B}X(\\omega)P(\\omega) $$\n",
    "\n",
    "<b>Definition:</b>\n",
    "\n",
    "Next we will define the expectation of $X$ conditional on a partition $\\mathcal{P}$ of $\\Omega$. Suppose\n",
    "that $P = {B_{1}, . . . , B_{K}}$ and that $P(B_{i}) \\neq 0, \\forall i = 1, . . . , K$. Note that for any random\n",
    "variable $Y$ measurable with respect to $\\sigma(P)$ we have that if $\\omega_{i} ∈ B_{j}$\n",
    "\n",
    "Note that for any random variable Y measurable with respect to \\sigma(P) we have that if \\omega_{i} \\in B_{j}\n",
    "\n",
    "$$ Y(\\omega_{i}) = E[Y\\mid B_{j}] $$\n",
    "\n",
    "since Y is constant on each B_{i}. This means that \n",
    "\n",
    "$$\n",
    "Y(\\omega) = \\sum_{i=1}^{K} E[Y\\mid B_{i}]\\cdot I_{B_{i}}(\\omega)\n",
    "$$\n",
    "\n",
    "<b> Definition </b> \n",
    "\n",
    "$$\n",
    "E[X\\mid \\mathcal{P}](\\omega) = \\sum_{i=1}^{K}E[X\\mid B_{i}] \\cdot I_{B_{i}}(\\omega)\n",
    "$$\n",
    "\n",
    "Remark: This means that E[X\\mid \\mathcal{P}] is a random variable Z such that\n",
    "\n",
    "- $Z \\in \\sigma(\\mathcal{P})$\n",
    "- $\\forall B \\in \\sigma(\\mathcal{P})$ we have that \n",
    "\n",
    "$$\n",
    "\\sum_{\\omega \\in B} Z(\\omega) P(\\omega) = \\sum_{\\omega \\in B}X(\\omega)P(\\omega)\n",
    "$$\n",
    "\n",
    "<b> Definition </b> Consider a random variabel $X$ on $(\\Omega, \\mathcal{F}, P)$ and a $\\sigma$-Algebra $\\mathcal{G}$ such that $\\mathcal{G} \\subseteq \\mathcal{F}$. The conditional expectation of $X$ given $\\mathcal{G}$ denoted $E[X\\mid \\mathcal{G}]$ is any random variable $Z$ that satisfy:\n",
    "\n",
    "- $Z \\in \\mathcal{G}$\n",
    "- $\\forall A \\in \\mathcal{G}$ we have that:\n",
    "\n",
    "$$\n",
    "\\sum_{\\omega \\in A} Z(\\omega) P(\\omega) = \\sum_{\\omega \\in A}X(\\omega)P(\\omega)\n",
    "$$\n",
    "\n",
    "<b>Proposition:</b> The conditional expectation has the following properties. Suppose that $X$ and $Y$ are random variables on $(\\Omega, \\mathcal{F}, P)$ and that $\\alpha, \\beta \\in \\mathbb{R}$. Let $\\mathcal{G}$ be a $\\sigma$-Algebra such that $\\mathcal{G} \\subseteq \\mathcal{F}$.\n",
    "\n",
    "1. Linearity: $E[\\alpha X + \\beta Y \\mid \\mathcal{G}] = \\alpha E[X\\mid \\mathcal{G}] + \\beta E[Y \\mid \\mathcal{G}]$\n",
    "\n",
    "2. Monotonicity: If $X \\leq Y$ then $E[X\\mid \\mathcal{G}] \\leq E[Y\\mid \\mathcal{G}]$\n",
    "\n",
    "3. $E[E[X \\mid \\mathcal{G}]] = E[X]$\n",
    "\n",
    "4. If $\\mathcal{H}$ is a $\\sigma$-Algebra such that $\\mathcal{H} \\subseteq \\mathcal{G} \\subseteq \\mathcal{F}$ then\n",
    "    - $E[E[X\\mid \\mathcal{H}]\\mid \\mathcal{G}] = E[X \\mid \\mathcal{H}]$\n",
    "    - $E[E[X\\mid \\mathcal{G}]\\mid \\mathcal{H}] = E[X \\mid \\mathcal{H}]$\n",
    "    \n",
    "5. Jensen's inequality. If $\\phi$ is a convex function, then \n",
    "\n",
    "$$\n",
    "\\phi(E[X\\mid \\mathcal{G}]) = E[\\phi(X) \\mid \\mathcal{G}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Martingales\n",
    "\n",
    "## Basics\n",
    "\n",
    "\n",
    "### Theory\n",
    "\n",
    "We begin directly with the definition of a martingale. \n",
    "\n",
    "<b> Definition: (Martingale) </b> A sequence $X = \\{ X_{n} \\}_{n=1}^{\\infty}$ of random variables is said to be a martingale with respect to the filtration $\\underline{\\mathcal{F}} = \\{ \\mathcal{F}_{n} \\}_{n \\geq 0}$ (or an $\\underline{\\mathcal{F}}$-martingale) if for all $n \\geq 0$:\n",
    "\n",
    "1. $X_{n} \\in \\mathcal{F}_{n}$\n",
    "2. $E[\\mid X_{n} \\mid] < \\infty$\n",
    "3. $E[X_{n+1}\\mid \\mathcal{F}_{n}]=X_{n}$\n",
    "\n",
    "<b> Lemma 1:</b> If $\\{ X_{n} \\}_{n=1}^{\\infty}$ for $n \\geq 0$ is a martingale with respect to $\\underline{\\mathcal{F}}$ then\n",
    "\n",
    "$$\n",
    "E[X_{n} \\mid \\mathcal{F}_{m}] = X_{m} \\text{for} n > m\n",
    "$$\n",
    "\n",
    "<b> Lemma 2:</b> Equivalence for all n $$E[X_{n+1}\\mid \\mathcal{F}_{n}]=X_{n} \\iff E[\\Delta X_{n} \\mid \\mathcal{F}_{n-1}]$$\n",
    "\n",
    "### Exemple\n",
    "\n",
    "Consider a sequence of tosses of a fair coin, and let\n",
    "\n",
    "$$\n",
    "U_{n}=\n",
    "\\begin{cases}\n",
    "1, \\text{if the n-th toss is heads}\\\\\n",
    "-1,  \\text{if the n-th toss is tails}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$U_{n}$ is basically the earnings if you bet 1 dollar on heads at coin number n. Now let \n",
    "\n",
    "$$X_{n} = \\sum_{i=1}^{n}U_{i}, n \\geq 1$$\n",
    "\n",
    "then $X_{n}$ represent the total earning after betting 1 dollar on head at each toss.\n",
    "\n",
    "Let $X_{0} = 0$ and let $\\mathcal{F}_{0} = \\{ \\emptyset , \\Omega \\}$ and $\\mathcal{F}_{n}=\\sigma(U_{1}, ..., U_{n}), n \\geq 1$\n",
    "\n",
    "<u>Claim:</u> $X_{n}, n \\geq 0$ is a martingale with respect to $\\underline{\\mathcal{F}} = \\{ \\mathcal{F}_{n} \\}_{n\\geq 0}$\n",
    "\n",
    "## Martingales transform\n",
    "\n",
    "### Theory\n",
    "\n",
    "The goal of this section is to show that a discrete time stochastic integral preserves the martingale property. We start by looking at an example. The point of the example is to show that there is no system for beating a fair game (represented by a martingale).\n",
    "\n",
    "<b>Definition: (Stochastic integral)</b>\n",
    "\n",
    "### Example (continuation)\n",
    "\n",
    "Now let H be a predictable process, i.e.\n",
    "\n",
    "$$ H_{n} \\in \\mathcal{F}_{n-1} $$\n",
    "\n",
    "H will represent our gambling strategy and thus for the $n$:th bet we may look at the outcomes at times $1,... ,n − 1$, but not at timen $n$, hence we require $H_{n}$ to be predictable. Specifically, $H_{n}$ should be the amount in dollars you bet at time $n$ on heads. Our winnings at time $n$ can be expressed using the stochastic integral:\n",
    "\n",
    "$$ (H \\cdot X)_{n} = \\sum_{m=1}^{n} H_{m} (X_{m} - X_{m-1}) = \\sum_{m=1}^{n} H_{m} U_{m} $$\n",
    "\n",
    "with the convention $(H \\cdot X)_{0} = 0$\n",
    "\n",
    "<b>Proposition:</b> Let $X = \\{ X_{n} \\}_{n=1}^{\\infty}$ be a amrtingale, and $\\{ H_{n} \\}_{n=1}^{\\infty}$ be a predictable process such that $\\mid H_{n}\\mid  \\leq M, n \\geq 1$. Then $\\{(H \\cdot X)_{n}\\}_{n=1}^{\\infty}$ is a martingale.\n",
    "\n",
    "<b>Corollary</b> Martingale properties imply $E[(H\\cdot X)_{n}] = 0$, meaning that there is no system for beating a fair game (with limited ressources)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "- In the first definition in the section conditional expectation, why are the probabilities normalized?\n",
    "\n",
    "- On partitions, why are measurable R.V. constant?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
